{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/storage')\n",
    "path = path/'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(path,\n",
    "                       download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(path,\n",
    "                      train = False ,\n",
    "                      download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=32,shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.nn.functional.mse_loss(yhat,y))\n",
    "#     return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "criterion = RMSELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(orignal,reconstructed):\n",
    "    pred = reconstructed.get('model_output')\n",
    "    \n",
    "    data_fidelity_loss = orignal * torch.log(1e-10 + pred) + (1 - orignal) * torch.log(1e-10 + 1 - pred)\n",
    "    data_fidelity_loss = -torch.sum(data_fidelity_loss)\n",
    "    \n",
    "    mu, sigma = reconstructed.get('mu'), reconstructed.get('sigma')\n",
    "    \n",
    "    kl_loss = 1  + sigma - torch.pow(mu,2) - torch.exp(sigma)\n",
    "    kl_loss = -0.5 * torch.sum(kl_loss)\n",
    "    \n",
    "    a,b = 1,1\n",
    "    \n",
    "    return (a*data_fidelity_loss + b*kl_loss) /2\n",
    "    \n",
    "criterion = vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.latent_size = 11\n",
    "        self.l1 = nn.Linear(28*28,499)\n",
    "        self.l2 = nn.Linear(499,359)\n",
    "        self.l3 = nn.Linear(359,209)\n",
    "        self.l4 = nn.Linear(209,99)\n",
    "#         self.l5 = nn.Linear(99,self.latent_size)\n",
    "        self.mu = nn.Linear(99,self.latent_size)\n",
    "        self.sigma = nn.Linear(99,self.latent_size)\n",
    "        self.l6 = nn.Linear(self.latent_size,99)\n",
    "        self.l7 = nn.Linear(99,209)\n",
    "        self.l8 = nn.Linear(209,359)\n",
    "        self.l9 = nn.Linear(359,499)\n",
    "        self.l10 = nn.Linear(499,28*28)\n",
    "        \n",
    "        self.fulyCnctdLayer = [self.l1, self.l2,\n",
    "                               self.l3, self.l4, \n",
    "                               self.mu, self.sigma, \n",
    "                               self.l6, self.l7, \n",
    "                               self.l8, self.l9,\n",
    "                              self.l10]\n",
    "        \n",
    "        self.drpt_layers = [nn.Dropout(.5),nn.Dropout(.5),nn.Dropout(.5),nn.Dropout(.5),nn.Dropout(.5),nn.Dropout(.5),\n",
    "                     nn.Dropout(.5),nn.Dropout(.5),nn.Dropout(.5),nn.Dropout(.5)]\n",
    "        \n",
    "        self.bthNrm_layers = [nn.BatchNorm1d(499), nn.BatchNorm1d(359), nn.BatchNorm1d(209), nn.BatchNorm1d(99),\n",
    "                                nn.BatchNorm1d(self.latent_size), nn.BatchNorm1d(self.latent_size),  \n",
    "                                 nn.BatchNorm1d(99), nn.BatchNorm1d(209), nn.BatchNorm1d(359), nn.BatchNorm1d(499),]\n",
    "    \n",
    "        \n",
    "    def basic_layer(self,x,layer_n,sigmoid=False):\n",
    "        L_layer  = self.fulyCnctdLayer[layer_n]\n",
    "        L_bthNrm = self.bthNrm_layers[layer_n]\n",
    "        L_drpt = self.drpt_layers[layer_n]\n",
    "        x = (L_bthNrm(L_drpt(L_layer(x))))\n",
    "        if not sigmoid: return torch.relu(x)\n",
    "        else: return torch.sigmoid(x)\n",
    "               \n",
    "    def forward(self,x):\n",
    "        x = self.basic_layer(x,0)\n",
    "        x = self.basic_layer(x,1)\n",
    "        x = self.basic_layer(x,2)\n",
    "        x = self.basic_layer(x,3)\n",
    "        mu = self.basic_layer(x,4)\n",
    "        sigma = self.basic_layer(x,5)\n",
    "        epsilon = torch.empty(self.latent_size).normal_(mean=0.,std=1.)\n",
    "        latent = mu + torch.exp(.5 + sigma)*epsilon\n",
    "        x = self.basic_layer(latent,6)\n",
    "        x = self.basic_layer(x,7)\n",
    "        x = self.basic_layer(x,8)\n",
    "        x = self.basic_layer(x,9)\n",
    "        x = torch.sigmoid(self.l10(x))\n",
    "        return {'model_output' : x ,\n",
    "               'mu' : mu,\n",
    "               'sigma' : sigma}\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.l1(x).relu()\n",
    "#         x = self.l2(x).relu()\n",
    "#         x = self.l3(x).relu()\n",
    "#         x = self.l4(x).relu()\n",
    "# #         x = self.l5(x).relu()\n",
    "\n",
    "#         mu_layer = self.mu(x).relu()\n",
    "#         sigma = self.sigma(x).relu()\n",
    "#         epsilon = torch.empty(11).normal_(mean=0.,std=1.)\n",
    "#         latent = mu_layer + torch.exp(.5 + sigma)*epsilon\n",
    "#         latent = latent\n",
    "\n",
    "#         x = self.l6(latent).relu()\n",
    "#         x = self.l7(x).relu()\n",
    "#         x = self.l8(x).relu()\n",
    "#         x = self.l9(x).relu()\n",
    "#         x = torch.sigmoid(self.l10(x))\n",
    "#         return x\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb31f7c4ae8a45ae8ee255584285599c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EPOCHS', max=3.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6a9016d8ba4931877731b61586494a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training Loop', max=1875.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr = 1e-3, weight_decay = 3e-3 )\n",
    "\n",
    "EPOCHS  = 3\n",
    "\n",
    "for e in tnrange(EPOCHS, desc='EPOCHS', leave='False', unit='Epoch'):\n",
    "    model.train()\n",
    "    for data in tqdm(trainset, desc='Training Loop', leave='False', unit='batch'):\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    loss_batch = [] \n",
    "    \n",
    "    for data in tqdm(testset, desc='Test Loop', leave='False', unit='batch'):\n",
    "        model.eval()\n",
    "        x,y = data\n",
    "        with torch.no_grad():\n",
    "            out = model(x.view(-1,28*28))\n",
    "            loss = criterion(x.view(-1,28*28),out)\n",
    "            loss_batch.append(loss.detach().numpy())\n",
    "        \n",
    "    tqdm_notebook.write(f'Epoch {e+1} loss => {np.mean([loss_batch])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),path/'model_3_epoch')\n",
    "torch.save(opt.state_dict(),path/'opt_3_epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(),path/'model_700_epoch')\n",
    "torch.save(opt.state_dict(),path/'opt_700_epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.load_state_dict(torch.load(path/'model_20_epoch'))\n",
    "opt.load_state_dict(torch.load(path/'opt_20_epoch'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr = 1e-3)\n",
    "\n",
    "EPOCHS  = 700\n",
    "\n",
    "for e in tnrange(EPOCHS, desc='EPOCHS', leave='False', unit='Epoch'):\n",
    "    model.train()\n",
    "    for data in tqdm(trainset, desc='Training Loop', leave='False', unit='batch'):\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    loss_batch = [] \n",
    "    \n",
    "    for data in tqdm(testset, desc='Test Loop', leave='False', unit='batch'):\n",
    "        model.eval()\n",
    "        x,y = data\n",
    "        with torch.no_grad():\n",
    "            out = model(x.view(-1,28*28))\n",
    "            loss = criterion(x.view(-1,28*28),out)\n",
    "            loss_batch.append(loss.detach().numpy())\n",
    "        \n",
    "    tqdm_notebook.write(f'Epoch {e+1} loss => {np.mean([loss_batch])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(),path/'model_1000_epoch')\n",
    "torch.save(opt.state_dict(),path/'opt_1000_epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr = 1e-3,weight_decay=1e-2)\n",
    "\n",
    "EPOCHS  = 1000\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    loss_batch = [] \n",
    "    \n",
    "    for data in testset:\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss_batch.append(loss.detach().numpy())\n",
    "        \n",
    "    print(np.mean([loss_batch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 0\n",
    "for data in testset:\n",
    "    x,y = data\n",
    "    out = model(x.view(-1,28*28))\n",
    "    break\n",
    "\n",
    "\n",
    "plt.imshow(np.reshape(out.get('model_output')[0].detach().numpy(),(-1,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.load_state_dict(torch.load(path/'model_20_epochs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opt = torch.optim.Adam(model.parameters(),lr = 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opt.load_state_dict(torch.load(path/'optim_20_epochs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "EPOCHS  = 1\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    loss_batch = [] \n",
    "    \n",
    "    for data in testset:\n",
    "        x,y = data\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss_batch.append(loss.detach().numpy())\n",
    "        \n",
    "    print(np.mean([loss_batch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "EPOCHS  = 1\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    loss_batch = [] \n",
    "    \n",
    "    for data in testset:\n",
    "        x,y = data\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss_batch.append(loss.detach().numpy())\n",
    "        \n",
    "    print(np.mean([loss_batch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "EPOCHS  = 5\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        x,y = data\n",
    "        model.zero_grad()\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    loss_batch = [] \n",
    "    \n",
    "    for data in testset:\n",
    "        x,y = data\n",
    "        out = model(x.view(-1,28*28))\n",
    "        loss = criterion(x.view(-1,28*28),out)\n",
    "        loss_batch.append(loss.detach().numpy())\n",
    "        \n",
    "    print(np.mean([loss_batch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(11).normal_(mean=0.,std=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " l = torch.exp(torch.ones(5))*(torch.ones(5)*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_storage = [torch.ones(1).normal_(mean=0.,std=1.),torch.ones(1).normal_(mean=0.,std=1.),\n",
    "                torch.ones(1).normal_(mean=0.,std=1.)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_storage[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/21583f6c4ca40e0ad9312e5bada60a42"
  },
  "gist": {
   "data": {
    "description": "storage/Practice_nbs/Pytorch/Gan.ipynb",
    "public": true
   },
   "id": "21583f6c4ca40e0ad9312e5bada60a42"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "433.4px",
    "left": "1223.6px",
    "right": "20px",
    "top": "120px",
    "width": "292.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
