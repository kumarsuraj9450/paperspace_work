{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_unfreeze(learner):\n",
    "    '''\n",
    "    Determines whether the next-to-last layer in the model is set to unfreeze or freeze\n",
    "    '''\n",
    "    c = 0\n",
    "    for each in list(learner.model[-2][0].parameters()):\n",
    "        if each.requires_grad: c += 1   \n",
    "    if c == len(list(learner.model[-2][0].parameters())):\n",
    "        return True \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def find_optimal_lr(learner, noise=3, show_df=None, show_min_values=False):\n",
    "    loss = np.array(learner.recorder.losses)\n",
    "    loss_grad = np.gradient(loss)   \n",
    "    # Transform lrs list to np array\n",
    "    lrs = np.array(learner.recorder.lrs, dtype='float32')\n",
    "\n",
    "    # Create a DataFrame with the data\n",
    "    data = {'loss': loss.T, 'loss_grad': loss_grad.T, 'lrs': lrs.T}\n",
    "    df = pd.DataFrame(data, columns=['loss', 'loss_grad', 'lrs', 'min_loss', 'max_loss', 'min_grad', 'max_grad'])\n",
    "\n",
    "    # Populate \"min\" and \"max\" columns for loss and gradient values filtering the noise with argrelextrema.     \n",
    "    from scipy.signal import argrelextrema\n",
    "\n",
    "    #********\n",
    "    # IMPORTANT: n filters noise (sharp spikes in the data). Higher n value filters noise more aggressively. \n",
    "    # n = 3 seems to work best\n",
    "    n=noise    \n",
    "    #********\n",
    "\n",
    "    df.min_loss = df.iloc[argrelextrema(df.loss.values, np.less_equal, order=n)[0]]['loss']\n",
    "    df.max_loss = df.iloc[argrelextrema(df.loss.values, np.greater_equal, order=n)[0]]['loss']\n",
    "    df.min_grad = df.iloc[argrelextrema(df.loss_grad.values, np.less_equal, order=n)[0]]['loss_grad']\n",
    "    df.max_grad = df.iloc[argrelextrema(df.loss_grad.values, np.greater_equal, order=n)[0]]['loss_grad']\n",
    "\n",
    "    # Optional: Display dataframe if show_df=True\n",
    "    if show_df == 'head': print(df.head(50)) \n",
    "    elif show_df == 'tail': print(df.tail(50))     \n",
    "\n",
    "    # Plot losses and loss gradients against lr values\n",
    "    plt.figure(figsize=[8, 5])\n",
    "    #figs, ax = plt.subplots(1,1)\n",
    "    ax = plt.gca()\n",
    "    color_loss = 'blue'\n",
    "    color_grad = 'orange'\n",
    "    color_green = 'green'\n",
    "    color_red = 'red'\n",
    "\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Learn Rate Finder')\n",
    "    ax.tick_params(axis='y', labelcolor=color_loss)\n",
    "    ax.semilogx(df.lrs, df.loss, c=color_loss, label='loss')\n",
    "\n",
    "    # Define variable vertical size of the plot window, depending on the graph shape\n",
    "    u_limit = max(df.loss.loc[(df.lrs < 0.1)].max(), 250)*2    \n",
    "    ax.set_ylim([-200, u_limit])\n",
    "\n",
    "    # Plot resulting line graphs\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylabel('loss', color= color_grad)\n",
    "    ax2.semilogx(df.lrs, df.loss_grad, c = color_grad, label='loss_grad')\n",
    "    ax2.tick_params(axis='y', labelcolor = color_grad)\n",
    "\n",
    "    # plot inflection points\n",
    "    ax.scatter(df.lrs, df.min_loss, c = color_red, label='min_loss')    \n",
    "    ax2.scatter(df.lrs, df.min_grad, c = color_red, label='min_grad')    \n",
    "    if show_min_values:\n",
    "        ax.scatter(df.lrs, df.max_loss, c = color_green, label='max_loss')\n",
    "        ax2.scatter(df.lrs, df.max_grad, c = color_green, label='max_grad') \n",
    "\n",
    "    # Legends\n",
    "    plt.LogFormatter(labelOnlyBase=False)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.0), ncol=3, fancybox=True, shadow=True)\n",
    "    ax2.legend(loc='upper center', bbox_to_anchor=(0.5, 0.9), ncol=3, fancybox=True, shadow=True)\n",
    "    plt.show()\n",
    "\n",
    "    # Display resulting lr values, format varies depending of te state of the model's next-to-last layer ggroup: set to freeze or unfreeze    \n",
    "    if is_unfreeze(learner):\n",
    "        # Yellow min_grad graph\n",
    "        rev_tru_idx = df.min_grad.notna()[::-1]   \n",
    "        optimun_lr_upper_bound_g = df.lrs.iloc[rev_tru_idx.idxmax()] \n",
    "        rev_tru_idx[rev_tru_idx.idxmax()] = np.NaN      \n",
    "        optimun_lr_lower_bound_1_g = df.lrs.iloc[rev_tru_idx.idxmax()]\n",
    "        rev_tru_idx[rev_tru_idx.idxmax()] = np.NaN      \n",
    "        optimun_lr_lower_bound_2_g = df.lrs.iloc[rev_tru_idx.idxmax()] \n",
    "\n",
    "        # Blue lass graph\n",
    "        rev_tru_idx_loss = df.min_loss.notna()[::-1]   \n",
    "        optimun_lr_upper_bound_l = df.lrs.iloc[rev_tru_idx_loss.idxmax()] \n",
    "        rev_tru_idx_loss[rev_tru_idx_loss.idxmax()] = np.NaN      \n",
    "        optimun_lr_lower_bound_1_l = df.lrs.iloc[rev_tru_idx_loss.idxmax()]\n",
    "        rev_tru_idx_loss[rev_tru_idx_loss.idxmax()] = np.NaN      \n",
    "        optimun_lr_lower_bound_2_l = df.lrs.iloc[rev_tru_idx_loss.idxmax()] \n",
    "\n",
    "        # Print results and return choices of lr slice\n",
    "        print('Model set to: \"unfreeze\" or \"freeze_to:\"')      \n",
    "        data = {'*Gradient - Orange Graph*' : [optimun_lr_upper_bound_g, optimun_lr_lower_bound_1_g, optimun_lr_lower_bound_2_g], \n",
    "          '*Loss - Blue Graph*' : [optimun_lr_upper_bound_l, optimun_lr_lower_bound_1_l, optimun_lr_lower_bound_2_l]}\n",
    "        prdf = pd.DataFrame(data, index = ['First choice lr:', 'Second choice lr:', 'Third choice lr:' ])\n",
    "        pd.options.display.float_format = '{:.10E}'.format\n",
    "\n",
    "        print(prdf)\n",
    "\n",
    "        return optimun_lr_lower_bound_1_g, optimun_lr_upper_bound_g\n",
    "\n",
    "    else:\n",
    "\n",
    "        optimun_lr_upper_bound = df.lrs.iloc[df.min_grad.notna()[::-1].idxmax()]\n",
    "        optimun_lr_lower_bound = df.lrs.iloc[df.min_loss.notna()[::-1].idxmax()]/10\n",
    "        # Print results and return optimal lr\n",
    "        print('Model set to \"freeze\":')\n",
    "        print('  Optimun lr: {:.10E} '.format(optimun_lr_upper_bound))\n",
    "        print('  Min loss divided by 10: {:.10E}'.format(optimun_lr_lower_bound))\n",
    "        return optimun_lr_upper_bound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=Path('/storage/planet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/storage/planet/train.7z'),\n",
       " PosixPath('/storage/planet/train.csv.7z')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.8.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/fastai\n",
      "\n",
      "  added / updated specs: \n",
      "    - eidl7zip\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    eidl7zip-1.0.0             |                1         565 KB  haasad\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    eidl7zip: 1.0.0-1 haasad\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "eidl7zip-1.0.0       | 565 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install --yes --prefix {sys.prefix} -c haasad eidl7zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "! 7za -bd -y -so x {path}/train.7z | tar xf - -C {path.as_posix()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames=get_image_files(path/'train-jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/storage/planet/train-jpg/train_24474.jpg')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fnames);\n",
    "fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(MultiCategoryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/fastai/lib/python3.6/site-packages/fastai/basic_data.py:262: UserWarning: There seems to be something wrong with your dataset, for example, in the first batch can't access any element of self.train_ds.\n",
      "Tried: 4,90,113,139,157...\n",
      "  warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "src = (ImageList.from_csv(path,'labels.csv')\n",
    "       .split_by_rand_pct(0.2)\n",
    "       .label_from_df(label_delim=' ')\n",
    "      .databunch().normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
